<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> ‘Filter Bubble Thesis’ Popped by Real-world Evidence | Will Rinehart</title>
  <meta name="description" content="My name is William Rinehart, but you can call me Will. Currently, I’m a Senior Research Fellow at the Center for Growth and Opportunity (CGO) at Utah State. Previously, I was the Director of Technology and Innovation Policy at the American Action Forum. In my day to day job, I specialize on the public policy of telecommunication, the Internet, platform companies, and AI, with a focus on emerging technologies and innovation. Fundamentally, I am interested in expanding human flourishing, reforming government to make it efficient, and learning.">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta property="og:title" content="‘Filter Bubble Thesis’ Popped by Real-world Evidence" />
<meta property="og:description" content="SOPA and PIPA overshadowed a number of newsworthy releases at the end of January, and in the scuffle, a study dissecting Facebook’s information networks seemed to have been lost. However, it lobbed an empirical salvo in the Filter Bubble war.
Working with Facebook, Eytan Bakshy, a newly-minted PhD in information theory, ran an experiment on the social network to better understand how individuals share information through their web of relations. Conducted over seven weeks in the summer of 2010, the experiment randomly suppressed links shared through the Facebook “Like” button—so some users wouldn’t see links that would normally have appeared in the Facebook “News Feed” of content shared by their friends." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://example.com/2012/filter-bubble-thesis-popped-by-real-world-evidence/" />
<meta property="article:published_time" content="2012-02-28T19:17:39+00:00" />
<meta property="article:modified_time" content="2012-02-28T19:17:39+00:00" />

  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="‘Filter Bubble Thesis’ Popped by Real-world Evidence"/>
<meta name="twitter:description" content="SOPA and PIPA overshadowed a number of newsworthy releases at the end of January, and in the scuffle, a study dissecting Facebook’s information networks seemed to have been lost. However, it lobbed an empirical salvo in the Filter Bubble war.
Working with Facebook, Eytan Bakshy, a newly-minted PhD in information theory, ran an experiment on the social network to better understand how individuals share information through their web of relations. Conducted over seven weeks in the summer of 2010, the experiment randomly suppressed links shared through the Facebook “Like” button—so some users wouldn’t see links that would normally have appeared in the Facebook “News Feed” of content shared by their friends."/>

  
  
    
  
  
  <link rel="stylesheet" href="https://example.com/css/style-white.css">
  
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
<link rel="icon" type="image/png" href="https://example.com/images/favicon.ico" />

  
  
  
</head>
<body class="max-width mx-auto px3 ltr">
  <div class="content index py4">

    <header id="header">
  <a href="https://example.com">
  
    <div id="logo" style="background-image: url(https://example.com/images/logo.png)"></div>
  
  <div id="title">
    <h1>Will Rinehart</h1>
  </div>
  </a>
  <div id="nav">
    <ul>
      <li class="icon">
        <a href="#"><i class="fas fa-bars fa-2x"></i></a>
      </li>
       
        <li><a href="/">Home</a></li>
       
        <li><a href="/posts">Blog</a></li>
       
        <li><a href="/publications">Publications</a></li>
       
        <li><a href="/media">Media</a></li>
       
        <li><a href="/about">About</a></li>
      
    </ul>
  </div>
</header>
  

    
<article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <div class="content" itemprop="articleBody">
  
    <p>SOPA and PIPA overshadowed a number of newsworthy releases at the end of January, and in the scuffle, a <a href="http://www.scribd.com/facebook/d/78445521-Role-of-Social-Networks-in-Information-Diffusion">study</a> dissecting Facebook’s information networks seemed to have been lost. However, it lobbed an empirical salvo in the <a href="http://www.google.com/url?q=http%3A%2F%2Ftechliberation.com%2F2011%2F06%2F07%2Fbook-review-eli-parisers-filter-bubble%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFiuQleylXtFmvom0qFwLZh3OVaaQ">Filter Bubble war</a>.</p>
<p>Working with Facebook, Eytan Bakshy, a newly-minted PhD in information theory, ran an experiment on the social network to better understand how individuals share information through their web of relations. Conducted over seven weeks in the summer of 2010, the experiment randomly suppressed links shared through the Facebook “Like” button—so some users wouldn’t see links that would normally have appeared in the Facebook “News Feed” of content shared by their friends. However, they weren’t completely cut off from these links, as users could still share links through information outlets other than Facebook.</p>
<p>Bakshy’s experiment was not a shot in the dark. In the early 1970s, sociology expanded into network theory when Mark Granovetter published his seminal paper, “<a href="http://www-new.stanford.edu/dept/soc/people/mgranovetter/documents/granstrengthweakties.pdf">The Strength of Weak Ties</a>.” Granovetter studied people who found jobs through personal contacts. Of those surveyed, nearly half said they found their then-current employment from someone that was was “not a friend, an acquaintance”—people that they knew, but had minimal contact with. From this, Granovetter correctly surmised that the people we are not close to (what he called weak ties) play an extremely important role in social cohesion and information sharing.</p>
<p>People who are similar tend to interact with one another. Homophily, as this is called, is a well known social dynamic. Conversely, those who do not interact often tend to be dissimilar, which also extends to the kind of information that they have. As Granovetter helped to show, weak ties tend to have novel information, and thus when the gap between clusters of close relations are bridged, novel information flows between the two groups. However because this doesn’t often occur, any particular piece of information is less likely to flow between two groups.</p>
<p>As Bakshy explains in his <a href="http://www.facebook.com/notes/facebook-data-team/rethinking-information-diversity-in-networks/10150503499618859">summary</a> posted on Facebook,</p>
<!-- raw HTML omitted -->
<p>This finding seriously undermines a number of arguments proclaiming the Internet has a tendency to trap us in echo-chambers. In the most recent example, <em>The Filter Bubble</em>, Eli Pariser questioned the benefits of personalized content like Facebook’s EdgeRank algorithm, Netflix’s movie suggestions and Amazon’s book recommendations. Pariser argued these “filters” narrow the range of voices to which users are exposed, fracturing the “marketplace of ideas” and “enclosing” or “feudalizing” our society’s discourse about key subjects. Pariser should be commended for taking the bulwarks of communication theory (framing, agenda setting, and priming) seriously, but filtering is considerably different problem than media scarcity. Where we now filter views, previously there just wasn’t as many views expressed.</p>
<p>Pariser’s worries are similarly echoed by Cass Sunstein, who noted in <em>Republic.com</em>, that the Internet allows “people [to] restrict themselves to their own points of view—liberals watching and reading mostly or only liberals; moderates, moderates; conservatives, conservatives; Neo-Nazis, Neo-Nazis,” resulting in fewer of the “unplanned, unanticipated encounters central to democracy itself.”</p>
<p>While there is still much to learn about information processing, we know that Facebook and other social networking sites have the tendency <a href="http://mvirtual.com.br/midiaedu/artigos_online/facebook.pdf">to increase weak ties</a>, which, as Bakshy shows, will tend to increase the exposure to novel information.</p>
<p>These notions of feudalizing social discourse are also not informed by history. In <em>The Good Citizen</em>, the most nuanced history of citizenship available, Michael Schudson documents the transformation in our expectations of citizenship. He takes on the idealized “informed citizen,” which, as he rightly points out, was not an expectation in eighteenth-century political circles. Rather, it took hold in the later part of the nineteenth century as education began to spread, finally becoming the yardstick it is today when the Progressives coupled public education and civic participation. His telling of the transformation of late 19th century politics reads as a warning to those who think we are losing the “unplanned, unanticipated encounters central to democracy itself,”</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>Schudsen’s history and Bakshy’s research, as well as <a href="http://faculty.chicagobooth.edu/matthew.gentzkow/research/echo_chambers.pdf">others</a>, suggest a longer trend in knowledge—rather than becoming more constrained in their views, people are actually becoming more informed about a wide diversity of opinions.</p>
<p>Unsurprisingly, Slate’s <a href="http://www.slate.com/articles/technology/technology/2012/01/online_echo_chambers_a_study_of_250_million_facebook_users_reveals_the_web_isn_t_as_polarized_as_we_thought_.single.html">coverage</a> attempts to undermine the study’s credibility:</p>
<!-- raw HTML omitted -->
<p>Although longstanding theory actually predicts this outcome, the benefit for Facebook is far greater than most are pointing out in their coverage (as is the reputational benefit for a network researcher in a tight PhD labor market). Not only does Facebook gets concrete information about the diffusion of information on <em>their</em> social network, it dispels a growing source of concern about Facebook’s effects on society—and, indeed, suggests Facebook probably increases the diversity of our experiences of the world.</p>
<p>Ultimately, this study complements the nuanced view that serious network theorists, communication scholars and psychologists are constructing about knowledge acquisition on the Internet, a nuance that can hardly be extended to policy prescriptions meant to “pop the filter bubbles.” Evgeny Morozov recently <a href="http://www.slate.com/articles/technology/future_tense/2012/01/anti_vaccine_activists_9_11_deniers_and_google_s_social_search_.single.html">suggested</a> that we should  “nudge search engines to take more responsibility for their index and exercise a heavier curatorial control in presenting search results for issues like ‘global warming’ or ‘vaccination.’” Beyond the obvious first amendment issues, Morozov drastically simplifies how information is gathered online. It could be that simple solutions solve complex issues, but having an incomplete grasp of informational diffusion on social networks will never allow for those solutions to be realistic.</p>
<p> </p>

  
  </div>
</article>


    <footer id="footer">
  <div class="footer-left">
    Copyright  &copy; 2020  Will Rinehart | economist, speaker, and analyst of tech policy 
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
        <li><a href="/">Home</a></li>
         
        <li><a href="/posts">Blog</a></li>
         
        <li><a href="/publications">Publications</a></li>
         
        <li><a href="/media">Media</a></li>
         
        <li><a href="/about">About</a></li>
        
      </ul>
    </nav>
  </div>
</footer>


  </div>
  
</body>

<link rel="stylesheet" href=/lib/font-awesome/css/all.min.css>
<script src=/lib/jquery/jquery.min.js></script>
<script src=/js/main.js></script>
</html>
