---
title: Towards a More Robust Understanding of Algorithmic Filtering
author: Will
type: post
date: -001-11-30T00:00:00+00:00
draft: true
url: /?p=1236
categories:
  - Uncategorized

---
Algorithm filtering has been a topic of discussion, and it&#8217;s understandable why. We increasingly live our lives on the Internet&#8217;s various sites like Facebook and Twitter. Naturally we wonder what is happening behind the black box.

Algorithms that filter and serve content are endemic on the Internet. Google overtook the rest of the

On one hand, many worry that we are experiencing a so called flood of information that is destroying our older, &#8220;normal&#8221; method of thinking and living. At the same time, algorithmic filters are being employed to serve content.

**The Economics of Algorithmic Filtering**

Search costs are just that, they are costly.

Knowledge capital depreciation: michael mandel has a lot to say about this.

Kirzner and discovery process / costs

Todays world is

<p style="padding-left: 30px;">
  In the West, knowledge begins as a winnowing process. It goes back to ancient Greece, where the rich, free menfolk were debating politics and steering the state. Many opinions were expressed, but only some of them were true, so knowledge became the winnowing of those opinions defined to be rare gems of truth. That idea — that knowledge is what makes it through a winnowing process — not by coincidence fits perfectly with the paper medium that we used for it. Paper is expensive, libraries are small, very few people can get published. So we’ve thought of knowledge as that which makes it through a very small aperture.
</p>

As Chetfield articulates, &#8220;_Ours is the first epoch of the articulate crowd, the smart mob: of words and deeds fused into ceaseless feedback.&#8221;_

Tyler Cowen explains:

<p style="padding-left: 30px;">
  [Carr] missed how people can construct wisdom — and long-term dramatic interest in their own self-education–from accumulating, collecting, and ordering small bits of information. What we’re growing impatient with is bits that are fed to us and that we really do not want.
</p>

Useful information, information that pushes forward a project or make a difference in saving lives is costly and has always been costly. Concerns about too much or too little information are orthogonal to a more important line of questioning: what are the costs in searching for the answer.

&nbsp;

Ethan Zuckerman  from [Wilson Quaterly][1]:

<p style="padding-left: 30px;">
  There are at least three ways we discover new information online. Each of these methods has shortcomings in terms of giving us a broad, global picture of the world. Search engines, while incredibly powerful, are only as good as the queries we put to them. They are designed for information retrieval, not for discovery. If you had been able to ask Google in 1979 how many SS-9 missiles the Soviets possessed, you might have received a plausible answer, but you wouldn’t have been told you should be asking about cassette recorders in Iran instead. Search engines tell us what we want to know, but they can’t tell us what we might need to know.
</p>

Social media such as Facebook or Twitter might tell you to pay attention to cassette recordings in Iran, but only if your friends include Iranians. Social media are a powerful discovery engine, but what you’re discovering is what your friends know. If you’re lucky enough to have a diverse, knowledgeable set of friends online, they may lead you in unexpected directions. But birds of a feather flock together, both online and offline, and your friends are more likely to help you discover the unexpected in your hometown than in another land.

The most powerful discovery engines online may be curated publications such as The New York Times or The Guardian. Editors of these publications are driven by a mission to provide their audiences with the broad picture of the world they need in order to be effective citizens, consumers, and businesspeople. But professional curators have their inevitable biases and blind spots. Much as we know to search for the news we think will affect our lives, editors deploy reporting resources toward parts of the world with strategic and economic significance. When mysteries unfold in corners of the world we’re used to ignoring, such as Tunisia, curators are often left struggling to catch up.

The limits of online information sources are a challenge both for us and for the people building the next generation of online tools. If we rigorously examine the media we’re encountering online, looking for topics and places we hear little about, we may be able to change our behavior, adding different and dissenting views to our social networks, seeking out new sources of news. But this task would be vastly easier if the architects of Internet tools took up the cause of helping to broaden worldviews. Facebook already notices that you’ve failed to “friend” a high school classmate and tries to connect you. It could look for strangers in Africa or India who share your interests and broker an introduction. Google tracks every search you undertake so it can more effectively target ads to you. It could also use that information to help you discover compelling content about topics you’ve never explored, adding a serendipity engine to its formidable search function.

&nbsp;

The darker side of the unfiltered feed:

<p style="padding-left: 30px;">
  No one will argue that Twitter played an imperative role in <a style="color: #326891;" href="http://www.nytimes.com/2014/08/18/business/media/view-of-ferguson-thrust-michael-brown-shooting-to-national-attention.html">ensuring that the events</a> in Ferguson led to an international debate about police violence and race in America. But it was also responsible for creating and perpetuating numerous falsehoods. What’s worse, Twitter users sought out and shared accounts that aligned with their viewpoint, with little regard to whether they were true.
</p>

Some interesting points:

  * Should we have
  * How does the concept of free speech interact with this? A lot of people don&#8217;t understand free speech
  * How does counter-speech interact here?

&nbsp;

And yet in Furgeson, here was the real issue: http://www.vox.com/xpress/2014/11/3/7147147/michael-brown-shooting-protests-journalists

http://thenewinquiry.com/blogs/marginal-utility/the-silence-of-the-masses-could-be-social-media/

&nbsp;

http://www.nickdiakopoulos.com/wp-content/uploads/2011/07/Algorithmic-Accountability-Reporting_final.pdf

&nbsp;

  * <http://www.theatlantic.com/technology/archive/2010/10/how-the-facebook-news-feed-algorithm-shapes-your-friendships/64996/>
  * <http://www.thedailybeast.com/articles/2010/10/18/the-facebook-news-feed-how-it-works-the-10-biggest-secrets.html>

&nbsp;

The Algorithm represents, in some key ways, the alienation

  * The alienation of people to objects
  * At what point do the things we do online get away from us?
  * High frequency trading?
  * 

&nbsp;

 [1]: http://archive.wilsonquarterly.com/essays/small-world-after-all