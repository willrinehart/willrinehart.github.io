---
title: ‘Filter Bubble Thesis’ Popped by Real-world Evidence
author: Will
type: post
date: 2012-02-28T19:17:39+00:00
url: /2012/filter-bubble-thesis-popped-by-real-world-evidence/
categories:
  - Communication Theory
  - Law
  - Mobile Tech
  - Network Industries
  - Network Theory
  - Research
  - Social Media
  - 'Sociology &amp; Psychology'
  - The Algorithm

---
SOPA and PIPA overshadowed a number of newsworthy releases at the end of January, and in the scuffle, a [study][1] dissecting Facebook’s information networks seemed to have been lost. However, it lobbed an empirical salvo in the [Filter Bubble war][2].

Working with Facebook, Eytan Bakshy, a newly-minted PhD in information theory, ran an experiment on the social network to better understand how individuals share information through their web of relations. Conducted over seven weeks in the summer of 2010, the experiment randomly suppressed links shared through the Facebook &#8220;Like&#8221; button—so some users wouldn&#8217;t see links that would normally have appeared in the Facebook &#8220;News Feed&#8221; of content shared by their friends. However, they weren&#8217;t completely cut off from these links, as users could still share links through information outlets other than Facebook.

Bakshy’s experiment was not a shot in the dark. In the early 1970s, sociology expanded into network theory when Mark Granovetter published his seminal paper, “[The Strength of Weak Ties][3].” Granovetter studied people who found jobs through personal contacts. Of those surveyed, nearly half said they found their then-current employment from someone that was was “not a friend, an acquaintance”—people that they knew, but had minimal contact with. From this, Granovetter correctly surmised that the people we are not close to (what he called weak ties) play an extremely important role in social cohesion and information sharing.

People who are similar tend to interact with one another. Homophily, as this is called, is a well known social dynamic. Conversely, those who do not interact often tend to be dissimilar, which also extends to the kind of information that they have. As Granovetter helped to show, weak ties tend to have novel information, and thus when the gap between clusters of close relations are bridged, novel information flows between the two groups. However because this doesn’t often occur, any particular piece of information is less likely to flow between two groups.

As Bakshy explains in his [summary][4] posted on Facebook,

<p style="padding-left: 30px;">
  We found that even though people are more likely to consume and share information that comes from close contacts that they interact with frequently (like discussing a photo from last night’s party), the vast majority of information comes from contacts that they interact with infrequently.  These distant contacts are also more likely to share novel information, demonstrating that social networks can act as a powerful medium for sharing new ideas, highlighting new products and discussing current events.
</p>

This finding seriously undermines a number of arguments proclaiming the Internet has a tendency to trap us in echo-chambers. In the most recent example, _The Filter Bubble_, Eli Pariser questioned the benefits of personalized content like Facebook’s EdgeRank algorithm, Netflix’s movie suggestions and Amazon’s book recommendations. Pariser argued these &#8220;filters&#8221; narrow the range of voices to which users are exposed, fracturing the &#8220;marketplace of ideas&#8221; and &#8220;enclosing&#8221; or &#8220;feudalizing&#8221; our society&#8217;s discourse about key subjects. Pariser should be commended for taking the bulwarks of communication theory (framing, agenda setting, and priming) seriously, but filtering is considerably different problem than media scarcity. Where we now filter views, previously there just wasn’t as many views expressed.

Pariser’s worries are similarly echoed by Cass Sunstein, who noted in _Republic.com_, that the Internet allows “people [to] restrict themselves to their own points of view—liberals watching and reading mostly or only liberals; moderates, moderates; conservatives, conservatives; Neo-Nazis, Neo-Nazis,” resulting in fewer of the “unplanned, unanticipated encounters central to democracy itself.”

While there is still much to learn about information processing, we know that Facebook and other social networking sites have the tendency [to increase weak ties][5], which, as Bakshy shows, will tend to increase the exposure to novel information.

These notions of feudalizing social discourse are also not informed by history. In _The Good Citizen_, the most nuanced history of citizenship available, Michael Schudson documents the transformation in our expectations of citizenship. He takes on the idealized “informed citizen,” which, as he rightly points out, was not an expectation in eighteenth-century political circles. Rather, it took hold in the later part of the nineteenth century as education began to spread, finally becoming the yardstick it is today when the Progressives coupled public education and civic participation. His telling of the transformation of late 19th century politics reads as a warning to those who think we are losing the “unplanned, unanticipated encounters central to democracy itself,”

<p style="padding-left: 30px;">
  Both sides of this political equation—on the one side, lively political campaign and deeply held political loyalties; on the other, a politics light on ideas or efforts to arrive at a public good, a politics of sections, jobbery, ethnic, racial, and religious scares and slurs—must be recognized as one of the cultural contradictions of democracy&#8230;
</p>

<p style="padding-left: 30px;">
  [As the power of the partisan press begun to diminish] the act of reading a newspaper and the process of political education changed; the discourse of citizenship and citizenship ideals was transformed. The outcome was a world in many respects more democratic, inclusive, and dedicated to public collective goals, and, for all that, less politically engaging.
</p>

Schudsen’s history and Bakshy&#8217;s research, as well as [others][6], suggest a longer trend in knowledge—rather than becoming more constrained in their views, people are actually becoming more informed about a wide diversity of opinions.

Unsurprisingly, Slate’s [coverage][7] attempts to undermine the study’s credibility:

<p style="padding-left: 30px;">
  At the same time, there’s an obvious problem with Bakshy’s study: It could only occur with the express consent of Facebook, and in the end it produced a result that is clearly very positive for the social network&#8230; If Bakshy’s experiment had come to the opposite conclusion—that, say, the News Feed does seem to echo our own ideas—I suspect they wouldn’t be publicizing it at all.
</p>

Although longstanding theory actually predicts this outcome, the benefit for Facebook is far greater than most are pointing out in their coverage (as is the reputational benefit for a network researcher in a tight PhD labor market). Not only does Facebook gets concrete information about the diffusion of information on _their_ social network, it dispels a growing source of concern about Facebook’s effects on society—and, indeed, suggests Facebook probably increases the diversity of our experiences of the world.

Ultimately, this study complements the nuanced view that serious network theorists, communication scholars and psychologists are constructing about knowledge acquisition on the Internet, a nuance that can hardly be extended to policy prescriptions meant to “pop the filter bubbles.” Evgeny Morozov recently [suggested][8] that we should  “nudge search engines to take more responsibility for their index and exercise a heavier curatorial control in presenting search results for issues like ‘global warming’ or ‘vaccination.’” Beyond the obvious first amendment issues, Morozov drastically simplifies how information is gathered online. It could be that simple solutions solve complex issues, but having an incomplete grasp of informational diffusion on social networks will never allow for those solutions to be realistic.

&nbsp;

 [1]: http://www.scribd.com/facebook/d/78445521-Role-of-Social-Networks-in-Information-Diffusion
 [2]: http://www.google.com/url?q=http%3A%2F%2Ftechliberation.com%2F2011%2F06%2F07%2Fbook-review-eli-parisers-filter-bubble%2F&sa=D&sntz=1&usg=AFQjCNFiuQleylXtFmvom0qFwLZh3OVaaQ
 [3]: http://www-new.stanford.edu/dept/soc/people/mgranovetter/documents/granstrengthweakties.pdf
 [4]: http://www.facebook.com/notes/facebook-data-team/rethinking-information-diversity-in-networks/10150503499618859
 [5]: http://mvirtual.com.br/midiaedu/artigos_online/facebook.pdf
 [6]: http://faculty.chicagobooth.edu/matthew.gentzkow/research/echo_chambers.pdf
 [7]: http://www.slate.com/articles/technology/technology/2012/01/online_echo_chambers_a_study_of_250_million_facebook_users_reveals_the_web_isn_t_as_polarized_as_we_thought_.single.html
 [8]: http://www.slate.com/articles/technology/future_tense/2012/01/anti_vaccine_activists_9_11_deniers_and_google_s_social_search_.single.html